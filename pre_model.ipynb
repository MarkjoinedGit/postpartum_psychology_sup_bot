{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download file GGUF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PINECONE_API_KEY'] = \"73bdec39-1f93-47fc-bd2f-f02883d7be83\"\n",
    "pinecone_api_key = os.getenv('PINECONE_API_KEY')\n",
    "pinecone_api_key\n",
    "os.environ[\"SERPER_API_KEY\"] = \"caabb8481fd9568ce9e4f6149139098b7fd91f85\"\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document as lcDocument\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from bs4 import BeautifulSoup\n",
    "from readability import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import re\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tải xuống: 100.00%\n",
      "Tệp đã được tải xuống và lưu tại models\\Llama-3.1-MedPalm2-imitate-8B-Instruct.Q8_0.gguf\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "url = 'https://huggingface.co/mradermacher/Llama-3.1-MedPalm2-imitate-8B-Instruct-GGUF/resolve/main/Llama-3.1-MedPalm2-imitate-8B-Instruct.Q8_0.gguf?download=true'\n",
    "save_directory = 'models'\n",
    "filename = 'Llama-3.1-MedPalm2-imitate-8B-Instruct.Q8_0.gguf'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "file_path = os.path.join(save_directory, filename)\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    print(f'Tệp {filename} đã tồn tại trong thư mục {save_directory}.')\n",
    "else:\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        total_size = int(response.headers.get('content-length', 0))  # Total size in bytes\n",
    "        block_size = 8192  # Download in chunks of 8KB\n",
    "        progress = 0  # Track the progress\n",
    "\n",
    "        with open(file_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=block_size):\n",
    "                if chunk:\n",
    "                    file.write(chunk)\n",
    "                    progress += len(chunk)\n",
    "                    percent_complete = (progress / total_size) * 100\n",
    "                    print(f'Tải xuống: {percent_complete:.2f}%', end='\\r')\n",
    "\n",
    "        print(f'\\nTệp đã được tải xuống và lưu tại {file_path}')\n",
    "    else:\n",
    "        print('Có lỗi xảy ra trong quá trình tải xuống.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call model via API (llama_cpp server) with Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(base_url=\"http://zep.hcmute.fit/7500/v1\", api_key=\"llama.cpp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Offline_RAG Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebSearchDB():\n",
    "    def __init__(self):\n",
    "        self.embedding = HuggingFaceEmbeddings()\n",
    "        self.db = self.build_db()\n",
    "        self.text_slit = RecursiveCharacterTextSplitter(\n",
    "                            separators = [\"\\n\\n\", \"\\n\", \" \", \".\", \",\", \"\\u200b\", \"\\u3001\", \"\\uff0e\", \"\\u3002\", \"\"],\n",
    "                            chunk_size = 500,\n",
    "                            chunk_overlap = 50,\n",
    "                            length_function = len,\n",
    "                            is_separator_regex = False)\n",
    "\n",
    "    def build_db(self):\n",
    "        db = PineconeVectorStore.from_existing_index(\n",
    "            index_name=\"docs-rag-chatbot\",\n",
    "            namespace=\"docs-link\",\n",
    "            embedding=self.embedding\n",
    "        )\n",
    "        return db\n",
    "    \n",
    "    def is_not_existed_url(self, url):\n",
    "        results = self.db.similarity_search(query=url, namespace=\"docs-link\", k=1)\n",
    "        if results[0].page_content == url:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def store_pinecone(self, docs, namespace):\n",
    "        if docs:\n",
    "            db = PineconeVectorStore.from_documents(documents=docs, embedding=self.embedding, index_name=\"docs-rag-chatbot\", namespace=namespace)\n",
    "\n",
    "    def store_web_content(self, web_links):\n",
    "        documents = []\n",
    "        if web_links:\n",
    "            for link in web_links:\n",
    "                content, title = self.read_content_from_web(link)\n",
    "                chunks = self.text_slit.split_documents(content)\n",
    "                cleaned_chunks = self.clean_data(chunks)\n",
    "            \n",
    "                for i, chunk in enumerate(cleaned_chunks):\n",
    "                    doc = lcDocument(\n",
    "                        page_content=chunk,\n",
    "                        metadata={\"source\": title, \"chunk_id\": i}\n",
    "                    )\n",
    "                    documents.append(doc)\n",
    "\n",
    "            self.store_pinecone(documents, 'docs-web-content')\n",
    "\n",
    "    def clean_data(self, chunks):\n",
    "        cleaned_chunks = []\n",
    "        for chunk in chunks:\n",
    "            cleaned_content = chunk.page_content.replace(\"\\n\", \" \")\n",
    "            cleaned_content = re.sub(r'\\s+', ' ', chunk.page_content)\n",
    "            cleaned_content = cleaned_content.strip()\n",
    "            cleaned_chunks.append(lcDocument(page_content=cleaned_content, metadata=chunk.metadata))\n",
    "        return cleaned_chunks\n",
    "        \n",
    "    def read_content_from_web(self, url):\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            doc = Document(response.content)\n",
    "            html_content = doc.summary()\n",
    "            title = doc.title()\n",
    "            soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "            text_content = soup.get_text()\n",
    "            return text_content, title\n",
    "        return None, None\n",
    "\n",
    "    def add_url(self, results):    \n",
    "        links_document = []\n",
    "        links = []\n",
    "        for web in results['organic']:\n",
    "            if self.is_not_existed_url(web['link']):\n",
    "                link_doc = lcDocument(page_content=web['link'], metadata={'source': web['title']})\n",
    "                links_document.append(link_doc)\n",
    "                links.append(web['link'])\n",
    "        self.store_pinecone(links_document, namespace='docs-link')\n",
    "        self.store_web_content(links)\n",
    "\n",
    "    def get_retriever(self,\n",
    "                      search_type: str = 'similarity', \n",
    "                      search_kwargs: dict = {'k': 5}):\n",
    "        retriever = self.db.as_retriever(search_type=search_type, search_kwargs=search_kwargs)\n",
    "        return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "class Offline_RAG:\n",
    "    def __init__(self, llm) -> None:\n",
    "        self.llm = llm\n",
    "\n",
    "        self.history_chat =[]\n",
    "        \n",
    "        condense_question_template = \"\"\"\n",
    "        Với đoạn hội thoại sau và một câu hỏi tiếp theo, hãy diễn đạt lại câu hỏi tiếp theo để nó trở thành một câu hỏi độc lập.\n",
    "        \n",
    "        Lịch sử hội thoại:\n",
    "        {chat_history}\n",
    "        Câu hỏi tiếp theo: {question}\n",
    "        Câu hỏi độc lập:\"\"\"\n",
    "        \n",
    "        self.condense_question_prompt = ChatPromptTemplate.from_template(condense_question_template)\n",
    "\n",
    "        qa_template = \"\"\"\n",
    "        Bạn là trợ lý AI hỗ trợ về sức khoẻ tâm lý sau sinh. \n",
    "        Dựa vào nội dung gợi ý trả lời bên dưới, hãy đưa ra câu trả lời và lời khuyên phù hợp cho câu hỏi của họ.\n",
    "        Nếu bạn không biết câu trả lời, hãy nói không biết, đừng cố tạo ra câu trả lời.\n",
    "\n",
    "        Lịch sử hội thoại:\n",
    "        {chat_history}\n",
    "\n",
    "        Nội dung gợi ý trả lời:\n",
    "        {context}\n",
    "\n",
    "        Câu hỏi: {question}\n",
    "        \"\"\"\n",
    "\n",
    "        self.qa_prompt = ChatPromptTemplate.from_template(qa_template)\n",
    "\n",
    "    def get_chain(self, retriever):\n",
    "        rag_chain = ConversationalRetrievalChain.from_llm(\n",
    "            llm,\n",
    "            retriever,\n",
    "            condense_question_prompt=self.condense_question_prompt,\n",
    "            combine_docs_chain_kwargs={\n",
    "                \"prompt\": self.qa_prompt,\n",
    "            },\n",
    "            return_source_documents=True,\n",
    "        )\n",
    "        return rag_chain\n",
    "    \n",
    "    def add_history(self, user_chat, bot_chat):\n",
    "        self.history_chat.append((\"user\", user_chat))\n",
    "        self.history_chat.append((\"assistant\", bot_chat))\n",
    "        if len(self.history_chat) > 5:\n",
    "            self.history_chat.pop(0)\n",
    "    \n",
    "    def get_input_data(self,question):\n",
    "        search = GoogleSerperAPIWrapper()\n",
    "        search.k = 2\n",
    "        results = search.results(question)\n",
    "        WebSearchDB().add_url(results=results)\n",
    "        return {\n",
    "            \"chat_history\": self.history_chat,\n",
    "            \"question\": question\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the VectorDB class using Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\1THUMUCDAIHOC\\HOC_KY_7\\PROJECT_AI\\postpartum_psychology_sup_bot\\.env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "class VectorDB:\n",
    "    def __init__(self,\n",
    "                 embedding = HuggingFaceEmbeddings()) -> None:\n",
    "        os.environ['PINECONE_API_KEY'] = \"73bdec39-1f93-47fc-bd2f-f02883d7be83\"\n",
    "        self.pinecone_api_key = os.getenv('PINECONE_API_KEY')\n",
    "        self.embedding = embedding\n",
    "        self.db = self._build_db()\n",
    "    \n",
    "    def _build_db(self):\n",
    "        db = PineconeVectorStore.from_existing_index(\n",
    "            index_name=\"docs-rag-chatbot\",\n",
    "            namespace=\"docs-store\",\n",
    "            embedding=self.embedding\n",
    "        )\n",
    "        return db\n",
    "    \n",
    "    # tính similarity\n",
    "    def get_retriever(self,\n",
    "                      search_type: str = \"similarity\",\n",
    "                      search_kwargs: dict = {\"k\": 5}\n",
    "                      ):\n",
    "        retriever =self.db.as_retriever(search_type=search_type,\n",
    "                                        search_kwargs=search_kwargs)\n",
    "        return retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function build chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rag_chain(llm):\n",
    "    retriever = WebSearchDB().get_retriever()\n",
    "    off_rag = Offline_RAG(llm)\n",
    "    rag_chain = off_rag.get_chain(retriever)\n",
    "    return rag_chain, off_rag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not prompt and context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'Đau đầu, mệt mỏi, suy nghĩ tiêu cực sau sinh là bị bệnh gì?', 'history': '', 'response': 'Chào bạn! Tôi hiểu bạn đang lo lắng về những triệu chứng bạn đang trải qua sau khi sinh nở.  Đau đầu, mệt mỏi và suy nghĩ tiêu cực sau sinh là những triệu chứng rất phổ biến được gọi là **bệnh trầm cảm sau sinh** hoặc **baby blues**. \\n\\nTuy nhiên, tôi không phải là chuyên gia y tế nên tôi không thể chẩn đoán bệnh.  Điều quan trọng nhất là bạn cần đến gặp bác sĩ để được kiểm tra và tư vấn điều trị phù hợp. Bác sĩ có thể giúp bạn xác định nguyên nhân của những triệu chứng này và đưa ra lời khuyên tốt nhất cho trường hợp của bạn. \\n\\nHãy nhớ rằng, bạn không đơn độc và rất nhiều phụ nữ khác cũng trải qua những cảm xúc tương tự sau khi sinh con.  Đừng ngần ngại tìm kiếm sự trợ giúp từ người thân, bạn bè hoặc các chuyên gia y tế.\\n\\n\\n'}\n",
      "Time: 91.38202548027039\n",
      "{'input': 'Hiện tại tôi không có thời gian đi bác sĩ, con tôi cứ khóc hoài, có cách nào để cho nó ngủ ngoan không ?', 'history': 'Human: Đau đầu, mệt mỏi, suy nghĩ tiêu cực sau sinh là bị bệnh gì?\\nAI: Chào bạn! Tôi hiểu bạn đang lo lắng về những triệu chứng bạn đang trải qua sau khi sinh nở.  Đau đầu, mệt mỏi và suy nghĩ tiêu cực sau sinh là những triệu chứng rất phổ biến được gọi là **bệnh trầm cảm sau sinh** hoặc **baby blues**. \\n\\nTuy nhiên, tôi không phải là chuyên gia y tế nên tôi không thể chẩn đoán bệnh.  Điều quan trọng nhất là bạn cần đến gặp bác sĩ để được kiểm tra và tư vấn điều trị phù hợp. Bác sĩ có thể giúp bạn xác định nguyên nhân của những triệu chứng này và đưa ra lời khuyên tốt nhất cho trường hợp của bạn. \\n\\nHãy nhớ rằng, bạn không đơn độc và rất nhiều phụ nữ khác cũng trải qua những cảm xúc tương tự sau khi sinh con.  Đừng ngần ngại tìm kiếm sự trợ giúp từ người thân, bạn bè hoặc các chuyên gia y tế.\\n\\n\\n', 'response': 'Tôi hiểu bạn đang rất mệt mỏi và muốn bé ngủ ngon giấc.  Tuy nhiên, như tôi đã nói trước, tôi không phải là chuyên gia y tế và không thể đưa lời khuyên về chăm sóc trẻ sơ sinh. \\n\\nCó nhiều cách để giúp bé ngủ ngoan hơn, nhưng mỗi em bé đều khác nhau và điều gì hiệu quả với một em bé có thể không hiệu quả với em bé khác.  Bạn có thể thử những mẹo sau:\\n\\n* **Tạo môi trường ngủ yên tĩnh và tối:** Giảm thiểu tiếng ồn và ánh sáng xung quanh nơi bé ngủ.\\n* **Thực hiện thói quen trước khi ngủ:** Tắm nước ấm, massage nhẹ nhàng, hát ru hoặc đọc sách cho bé có thể giúp bé thư giãn và sẵn sàng ngủ.\\n* **Cho bé bú đầy đủ:**  Bé sẽ dễ ngủ hơn nếu đã no nê.\\n* **Dành thời gian chăm sóc bé:** Đôi khi bé khóc vì cần sự quan tâm và gần gũi của mẹ.\\n\\nTuy nhiên, nếu bé khóc liên tục hoặc có dấu hiệu bất thường, bạn nên liên hệ với bác sĩ hoặc chuyên gia chăm sóc trẻ sơ sinh để được tư vấn. \\n\\n\\n'}\n",
      "Time: 160.35926842689514\n",
      "Average time: 125.87064695358276\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "from langchain import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "import time\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory=memory\n",
    ")\n",
    "sum_time = 0\n",
    "n = 0\n",
    "while True:\n",
    "    question = input(\"You: \")\n",
    "\n",
    "    if question == \"exit\":\n",
    "        break\n",
    "\n",
    "    start = time.time()\n",
    "    response = conversation.invoke({\n",
    "            \"input\": question\n",
    "        })\n",
    "    end = time.time()\n",
    "\n",
    "    sum_time += end - start\n",
    "    n += 1\n",
    "\n",
    "    print(response)\n",
    "    \n",
    "    print(f\"Time: {end - start}\")\n",
    "\n",
    "print(f\"Average time: {sum_time/n}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'Đau đầu, mệt mỏi, suy nghĩ tiêu cực sau sinh là bị bệnh gì?', 'history': '', 'response': 'Tôi hiểu bạn đang cảm thấy rất khó khăn.  Đau đầu, mệt mỏi và suy nghĩ tiêu cực sau sinh là những triệu chứng thường gặp của **thoi ương trầm cảm** (postpartum depression).\\n\\nTuy nhiên, tôi không phải là chuyên gia y tế và không thể chẩn đoán bệnh. \\n\\n**Điều quan trọng nhất là bạn nên liên hệ với bác sĩ hoặc chuyên gia sức khỏe tâm thần để được tư vấn và hỗ trợ phù hợp.** Họ có thể giúp bạn xác định nguyên nhân của những triệu chứng bạn đang gặp phải và đưa ra phương pháp điều trị tốt nhất cho trường hợp của bạn.\\n\\nHãy nhớ rằng bạn không đơn độc và có rất nhiều nguồn lực sẵn sàng hỗ trợ bạn vượt qua giai đoạn này. \\n'}\n",
      "Time: 85.21116423606873\n",
      "{'input': 'Hiện tại tôi không có thời gian đi bác sĩ, con tôi cứ khóc hoài, có cách nào để cho nó ngủ ngoan không ?', 'history': 'Human: Đau đầu, mệt mỏi, suy nghĩ tiêu cực sau sinh là bị bệnh gì?\\nAI: Tôi hiểu bạn đang cảm thấy rất khó khăn.  Đau đầu, mệt mỏi và suy nghĩ tiêu cực sau sinh là những triệu chứng thường gặp của **thoi ương trầm cảm** (postpartum depression).\\n\\nTuy nhiên, tôi không phải là chuyên gia y tế và không thể chẩn đoán bệnh. \\n\\n**Điều quan trọng nhất là bạn nên liên hệ với bác sĩ hoặc chuyên gia sức khỏe tâm thần để được tư vấn và hỗ trợ phù hợp.** Họ có thể giúp bạn xác định nguyên nhân của những triệu chứng bạn đang gặp phải và đưa ra phương pháp điều trị tốt nhất cho trường hợp của bạn.\\n\\nHãy nhớ rằng bạn không đơn độc và có rất nhiều nguồn lực sẵn sàng hỗ trợ bạn vượt qua giai đoạn này. \\n', 'response': 'Tôi hiểu bạn đang trong một tình huống rất khó khăn và mệt mỏi.  Việc chăm sóc một em bé sơ sinh có thể rất áp lực, đặc biệt khi bạn đang cảm thấy đau đầu, mệt mỏi và suy nghĩ tiêu cực. \\n\\nTuy nhiên, tôi không phải là chuyên gia về việc chăm sóc trẻ sơ sinh và không thể đưa ra lời khuyên y tế. \\n\\n**Điều quan trọng là bạn nên ưu tiên sức khỏe của chính mình.** Hãy tìm một người có thể giúp bạn trông trẻ cho một lúc ngắn ngủi để bạn có thể nghỉ ngơi hoặc liên hệ với gia đình, bạn bè hoặc các nhóm hỗ trợ sau sinh để được sự trợ giúp.  \\n'}\n",
      "Time: 116.77633357048035\n",
      "Average time: 100.99374890327454\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "from langchain import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "qa_template = \"\"\"\n",
    "        Bạn là trợ lý AI hỗ trợ về sức khoẻ tâm lý sau sinh. \n",
    "        Hãy đưa ra câu trả lời và lời khuyên phù hợp cho câu hỏi của họ.\n",
    "        Nếu bạn không biết câu trả lời, hãy nói không biết, đừng cố tạo ra câu trả lời.\n",
    "\n",
    "        Lịch sử hội thoại:\n",
    "        {history}\n",
    "\n",
    "        Câu hỏi: {input}\n",
    "        \"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_template(qa_template)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory=memory,\n",
    "    prompt = qa_prompt\n",
    ")\n",
    "\n",
    "sum_time = 0\n",
    "n = 0\n",
    "\n",
    "while True:\n",
    "    question = input(\"You: \")\n",
    "    if question == \"exit\":\n",
    "        break\n",
    "    start = time.time()\n",
    "    response = conversation.invoke({\n",
    "            \"input\": question\n",
    "        })\n",
    "    end = time.time()\n",
    "    sum_time += end - start\n",
    "    n += 1\n",
    "    print(response)\n",
    "    print(f\"Time: {end - start}\")\n",
    "\n",
    "print(f\"Average time: {sum_time/n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\1THUMUCDAIHOC\\HOC_KY_7\\PROJECT_AI\\postpartum_psychology_sup_bot\\.env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "c:\\1THUMUCDAIHOC\\HOC_KY_7\\PROJECT_AI\\postpartum_psychology_sup_bot\\.env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chat_history': [], 'question': 'Làm sao để giảm stress', 'answer': 'Sau sinh, việc chăm sóc con nhỏ và những thay đổi trong cuộc sống có thể khiến bạn cảm thấy rất căng thẳng. \\n\\nMay mắn là có nhiều cách đơn giản mà hiệu quả để giúp bạn giảm stress sau sinh. Dưới đây là một số lời khuyên:\\n\\n* **Chăm sóc bản thân:** Hãy dành thời gian cho bản thân mỗi ngày, dù chỉ là 15 phút ngắn ngủi. Tắm, đọc sách, nghe nhạc, hoặc làm bất cứ điều gì bạn yêu thích để thư giãn và tái tạo năng lượng.\\n* **Ăn uống lành mạnh:** Chế độ ăn uống cân bằng sẽ giúp cơ thể bạn khỏe mạnh và có sức chịu đựng tốt hơn với stress. \\n* **Ngủ đủ giấc:** Thiếu ngủ sẽ làm tăng mức độ stress. Hãy cố gắng ngủ đủ 7-8 tiếng mỗi đêm, hoặc chia nhỏ giấc ngủ thành nhiều lần nếu con bạn thức suốt đêm.\\n* **Tập thể dục nhẹ nhàng:** Tập thể dục có thể giúp giảm căng thẳng và nâng cao tinh thần. Bạn có thể tập yoga, đi bộ nhẹ nhàng hoặc tham gia các lớp tập thể dục dành cho bà mẹ sau sinh.\\n* **Kết nối với người khác:** Chia sẻ cảm xúc và nỗi lo của bạn với người thân, bạn bè, hoặc nhóm hỗ trợ dành cho bà mẹ sau sinh. \\n* **Học cách nói \"không\":** Không nên tự ép mình làm mọi việc. Hãy học cách từ chối những yêu cầu không cần thiết để có thời gian thư giãn và chăm sóc bản thân.\\n* **Tìm kiếm sự giúp đỡ chuyên nghiệp:** Nếu bạn cảm thấy stress quá mức, hãy tìm kiếm sự giúp đỡ từ bác sĩ hoặc chuyên gia tâm lý.\\n\\n\\nHãy nhớ rằng bạn không phải đối mặt với stress sau sinh một mình.  Có rất nhiều nguồn lực có thể hỗ trợ bạn. \\n', 'source_documents': [Document(metadata={'source': '“Bỏ túi” những cách giảm stress hiệu quả và đơn giản nhất - Medlatec'}, page_content='https://medlatec.vn/tin-tuc/bo-tui-nhung-cach-giam-stress-hieu-qua-va-don-gian-nhat-s195-n21011'), Document(metadata={'source': 'Những cách giảm stress sau sinh hiệu quả mà bạn nên biết - YouMed'}, page_content='https://youmed.vn/tin-tuc/nhung-cach-giam-stress-sau-sinh-hieu-qua-ma-ban-nen-biet/'), Document(metadata={'source': 'Khắc phục tình trạng stress sau sinh - Hồng Ngọc'}, page_content='https://hongngochospital.vn/vi/khac-phuc-stress-sau-sinh'), Document(metadata={'source': '18 cách xả stress hiệu quả, giúp giảm bớt triệu chứng nhanh chóng'}, page_content='https://tamanhhospital.vn/xa-stress/'), Document(metadata={'source': '9 phương pháp giúp giảm căng thẳng sau khi sinh - Hello Bacsi'}, page_content='https://hellobacsi.com/mang-thai/cham-soc-me-sau-sinh/tam-ly-sau-sinh/9-cach-giup-giam-cang-thang-sau-sinh/')]}\n",
      "Time: 35.43514895439148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\1THUMUCDAIHOC\\HOC_KY_7\\PROJECT_AI\\postpartum_psychology_sup_bot\\.env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'page_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     10\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 11\u001b[0m response \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39minvoke(\u001b[43moff_rag\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_input_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     12\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     14\u001b[0m sum_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m end \u001b[38;5;241m-\u001b[39m start\n",
      "Cell \u001b[1;32mIn[78], line 58\u001b[0m, in \u001b[0;36mOffline_RAG.get_input_data\u001b[1;34m(self, question)\u001b[0m\n\u001b[0;32m     56\u001b[0m search\u001b[38;5;241m.\u001b[39mk \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     57\u001b[0m results \u001b[38;5;241m=\u001b[39m search\u001b[38;5;241m.\u001b[39mresults(question)\n\u001b[1;32m---> 58\u001b[0m \u001b[43mWebSearchDB\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory_chat,\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: question\n\u001b[0;32m     62\u001b[0m }\n",
      "Cell \u001b[1;32mIn[77], line 76\u001b[0m, in \u001b[0;36mWebSearchDB.add_url\u001b[1;34m(self, results)\u001b[0m\n\u001b[0;32m     74\u001b[0m         links\u001b[38;5;241m.\u001b[39mappend(web[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore_pinecone(links_document, namespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocs-link\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore_web_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinks\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[77], line 35\u001b[0m, in \u001b[0;36mWebSearchDB.store_web_content\u001b[1;34m(self, web_links)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m link \u001b[38;5;129;01min\u001b[39;00m web_links:\n\u001b[0;32m     34\u001b[0m     content, title \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_content_from_web(link)\n\u001b[1;32m---> 35\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_slit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m     cleaned_chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean_data(chunks)\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(cleaned_chunks):\n",
      "File \u001b[1;32mc:\\1THUMUCDAIHOC\\HOC_KY_7\\PROJECT_AI\\postpartum_psychology_sup_bot\\.env\\Lib\\site-packages\\langchain_text_splitters\\base.py:94\u001b[0m, in \u001b[0;36mTextSplitter.split_documents\u001b[1;34m(self, documents)\u001b[0m\n\u001b[0;32m     92\u001b[0m texts, metadatas \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents:\n\u001b[1;32m---> 94\u001b[0m     texts\u001b[38;5;241m.\u001b[39mappend(\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m)\n\u001b[0;32m     95\u001b[0m     metadatas\u001b[38;5;241m.\u001b[39mappend(doc\u001b[38;5;241m.\u001b[39mmetadata)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_documents(texts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'page_content'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "chain, off_rag = build_rag_chain(llm)\n",
    "sum_time = 0\n",
    "n = 0\n",
    "while True:\n",
    "    question = input(\"You: \")\n",
    "    if question == \"exit\":\n",
    "        break\n",
    "    \n",
    "    start = time.time()\n",
    "    response = chain.invoke(off_rag.get_input_data(question))\n",
    "    end = time.time()\n",
    "\n",
    "    sum_time += end - start\n",
    "    n += 1\n",
    "\n",
    "    print(response)\n",
    "    \n",
    "    off_rag.add_history(question, response[\"answer\"])\n",
    "\n",
    "    print(f\"Time: {end - start}\")\n",
    "\n",
    "print(f\"Average time: {sum_time/n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
